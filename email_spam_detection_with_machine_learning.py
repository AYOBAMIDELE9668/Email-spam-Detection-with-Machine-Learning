# -*- coding: utf-8 -*-
"""Email spam Detection with Machine Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xNDmZfCTFpMYso3l9tX2M3K5VspZ5lDD
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('spam.csv', encoding='latin-1')

print(df.head(5))

print(df.isnull().sum())

df = df[['v1', 'v2']]
df.columns = ['label', 'message']

print(df['label'].value_counts())

# Visualize the distribution
sns.countplot(x='label', data=df)
plt.title('Distribution of Spam vs Ham')
plt.show()

import string
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer

import nltk
nltk.download('stopwords')

# Define a function to clean the text
def clean_text(text):
    # Remove punctuation
    text = ''.join([char for char in text if char not in string.punctuation])
    # Convert to lowercase
    text = text.lower()
    # Remove stopwords
    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])
    return text

# Apply the cleaning function to the 'message' column
df['clean_message'] = df['message'].apply(clean_text)

# Convert text to numerical features using CountVectorizer
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df['clean_message']).toarray()

# Encode the labels (spam = 1, ham = 0)
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
y = encoder.fit_transform(df['label'])

# Check the shape of the feature matrix
print("\nShape of the feature matrix:", X.shape)

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Testing set shape:", X_test.shape)

from sklearn.naive_bayes import MultinomialNB

# Initialize and train the model
model = MultinomialNB()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model's performance
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Function to predict whether a new message is spam or ham
def predict_spam(message):
    # Clean the input message
    cleaned_message = clean_text(message)
    # Convert the message to numerical features
    message_vector = vectorizer.transform([cleaned_message]).toarray()
    # Predict the label
    prediction = model.predict(message_vector)
    return 'Spam' if prediction[0] == 1 else 'Ham'

# Test the function with a custom message
custom_message = "Congratulations! You've won a free iPhone. Click here to claim."
print("\nPrediction for custom message:", predict_spam(custom_message))

custom_message = "Hey, can we meet tomorrow?"
print("Prediction for custom message:", predict_spam(custom_message))

# Save the trained model and vectorizer for future use
import joblib

joblib.dump(model, 'spam_detector_model.pkl')
joblib.dump(vectorizer, 'vectorizer.pkl')

# To load the model later:
# model = joblib.load('spam_detector_model.pkl')
# vectorizer = joblib.load('vectorizer.pkl')